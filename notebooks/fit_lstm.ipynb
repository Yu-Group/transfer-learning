{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "from os.path import join as oj\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from functools import partial\n",
    "import pickle as pkl\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "import data\n",
    "import config\n",
    "import features\n",
    "import train_reg\n",
    "import neural_networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(oj(config.DIR_PROCESSED, 'df_full.pkl'))\n",
    "df = features.normalize_track(df, track='X_same_length', by_time_point=False) # adds X_same_length_normalized\n",
    "df = df[~df.short & ~df.hotspots] # filter out easy/invalid tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dset                    split\n",
       "clath_aux+gak           train     2018\n",
       "                        test       535\n",
       "clath_aux+gak_a7d2      train     3327\n",
       "                        test      1067\n",
       "clath_aux+gak_a7d2_new  train     7877\n",
       "                        test      1703\n",
       "clath_aux+gak_new       train     3404\n",
       "                        test       679\n",
       "clath_aux_dynamin       train    34559\n",
       "                        test      9367\n",
       "clath_gak               train     3496\n",
       "                        test      1498\n",
       "Name: split, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# each dataset has different number of cells each with different number of tracks\n",
    "# the 'split' variable says whether a track is in the train or test set\n",
    "df.groupby('dset')['split'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fit models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "for dset_name in df['dset'].unique():\n",
    "    d = df[(df['dset'] == dset_name) & (df['split'] == 'train')]\n",
    "    checkpoint_fname = oj(config.DIR_MODELS, 'dnn_individual', f'dnn_{dset_name}.pkl')\n",
    "    dnn = neural_networks.neural_net_sklearn(D_in=40, H=20, p=0, arch='lstm', epochs=100)\n",
    "    dnn.fit(X=d[['X_same_length_normalized']],\n",
    "            y=d['Y_sig_mean_normalized'].values,\n",
    "            verbose=False, checkpoint_fname=checkpoint_fname)\n",
    "    pkl.dump({'model_state_dict': dnn.model.state_dict()}, open(checkpoint_fname, 'wb'))\n",
    "    \n",
    "    # fit dasc\n",
    "    checkpoint_fname = oj(config.DIR_MODELS, 'dasc_individual', f'dasc_{dset_name}.pkl')\n",
    "    dasc_model = LinearRegression().fit(d['X_d1'].values.reshape(-1, 1), d['Y_sig_mean_normalized'])\n",
    "    pkl.dump(dasc_model, open(checkpoint_fname, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# look at model performance on corresponding test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>r2</th>\n",
       "      <th>acc</th>\n",
       "      <th>r2_dasc</th>\n",
       "      <th>acc_dasc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>clath_aux+gak</th>\n",
       "      <td>0.382298</td>\n",
       "      <td>0.691589</td>\n",
       "      <td>0.230255</td>\n",
       "      <td>0.710280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clath_aux+gak_a7d2</th>\n",
       "      <td>0.287640</td>\n",
       "      <td>0.722587</td>\n",
       "      <td>0.160431</td>\n",
       "      <td>0.545455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clath_aux+gak_a7d2_new</th>\n",
       "      <td>0.449184</td>\n",
       "      <td>0.512038</td>\n",
       "      <td>0.049070</td>\n",
       "      <td>0.722842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clath_aux+gak_new</th>\n",
       "      <td>0.399651</td>\n",
       "      <td>0.777614</td>\n",
       "      <td>0.174010</td>\n",
       "      <td>0.387334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clath_aux_dynamin</th>\n",
       "      <td>0.428417</td>\n",
       "      <td>0.725846</td>\n",
       "      <td>0.232492</td>\n",
       "      <td>0.442084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clath_gak</th>\n",
       "      <td>0.265840</td>\n",
       "      <td>0.654206</td>\n",
       "      <td>0.121623</td>\n",
       "      <td>0.542056</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              r2       acc   r2_dasc  acc_dasc\n",
       "clath_aux+gak           0.382298  0.691589  0.230255  0.710280\n",
       "clath_aux+gak_a7d2      0.287640  0.722587  0.160431  0.545455\n",
       "clath_aux+gak_a7d2_new  0.449184  0.512038  0.049070  0.722842\n",
       "clath_aux+gak_new       0.399651  0.777614  0.174010  0.387334\n",
       "clath_aux_dynamin       0.428417  0.725846  0.232492  0.442084\n",
       "clath_gak               0.265840  0.654206  0.121623  0.542056"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = {\n",
    "    'r2': [],\n",
    "    'acc': [],\n",
    "    'r2_dasc': [],\n",
    "    'acc_dasc': [],\n",
    "}\n",
    "dset_names = sorted(df['dset'].unique())\n",
    "for dset_name in dset_names:\n",
    "    # load models\n",
    "    dnn = neural_networks.neural_net_sklearn(D_in=40, H=20, p=0, arch='lstm')\n",
    "    ckpt = pkl.load(open(oj(config.DIR_MODELS, 'dnn_individual', f'dnn_{dset_name}.pkl'), 'rb'))\n",
    "    dnn.model.load_state_dict(ckpt['model_state_dict'])\n",
    "    dasc_model = pkl.load(open(oj(config.DIR_MODELS, 'dasc_individual', f'dasc_{dset_name}.pkl'), 'rb'))\n",
    "    \n",
    "    # test on test set\n",
    "    d = df[(df['dset'] == dset_name) & (df['split'] == 'test')]\n",
    "    preds_reg = dnn.predict(d[['X_same_length_normalized']])\n",
    "    preds_class = (preds_reg).astype(int)\n",
    "    preds_reg_dasc = dasc_model.predict(d['X_d1'].values.reshape(-1, 1))\n",
    "    scores['r2'].append(metrics.r2_score(d['Y_sig_mean_normalized'], preds_reg))\n",
    "    scores['acc'].append(metrics.accuracy_score(d['y_consec_thresh'], preds_class))\n",
    "    scores['r2_dasc'].append(metrics.r2_score(d['Y_sig_mean_normalized'], preds_reg_dasc))\n",
    "    scores['acc_dasc'].append(metrics.accuracy_score(d['y_consec_thresh'], (preds_reg_dasc > 0).astype(int)))    \n",
    "scores = pd.DataFrame.from_dict(scores)\n",
    "scores.index = dset_names\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# look at model performance on all test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset_names = sorted(df['dset'].unique())\n",
    "ks = []\n",
    "for d in dset_names:\n",
    "    ks += [f'r2_{d}', f'r2_dasc_{d}', f'acc_{d}', f'acc_dasc_{d}']\n",
    "scores = {\n",
    "    k: [] for k in ks\n",
    "}\n",
    "for dset_name in dset_names:\n",
    "    # load models\n",
    "    dnn = neural_networks.neural_net_sklearn(D_in=40, H=20, p=0, arch='lstm')\n",
    "    ckpt = pkl.load(open(oj(config.DIR_MODELS, 'dnn_individual', f'dnn_{dset_name}.pkl'), 'rb'))\n",
    "    dnn.model.load_state_dict(ckpt['model_state_dict'])\n",
    "    dasc_model = pkl.load(open(oj(config.DIR_MODELS, 'dasc_individual', f'dasc_{dset_name}.pkl'), 'rb'))\n",
    "    \n",
    "    # test on all test sets\n",
    "    for test_set_name in dset_names:\n",
    "        d = df[(df['dset'] == test_set_name) & (df['split'] == 'test')]\n",
    "        preds_reg = dnn.predict(d[['X_same_length_normalized']])\n",
    "        preds_class = (preds_reg).astype(int)\n",
    "        preds_reg_dasc = dasc_model.predict(d['X_d1'].values.reshape(-1, 1))\n",
    "        scores['r2'].append(metrics.r2_score(d['Y_sig_mean_normalized'], preds_reg))\n",
    "        scores['acc'].append(metrics.accuracy_score(d['y_consec_thresh'], preds_class))\n",
    "        scores['r2_dasc'].append(metrics.r2_score(d['Y_sig_mean_normalized'], preds_reg_dasc))\n",
    "        scores['acc_dasc'].append(metrics.accuracy_score(d['y_consec_thresh'], (preds_reg_dasc > 0).astype(int)))    \n",
    "scores = pd.DataFrame.from_dict(scores)\n",
    "scores.index = dset_names\n",
    "scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
